{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "functional_Week_4.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjvr-uYQ6mTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cb8c64-d7fe-48f9-d210-a52ff56e6f77"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxAcIEN6mTx"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJvfHztl6mTx"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QOD5Von6mTx"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pboLfV_H6mTx"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyeV0YYL6mTx"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u23mG5v_6mTx"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense_1 = Dense(64, activation=\"relu\")\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dense_3 = Dense(5)\n",
        "    self.softmax = Softmax()\n",
        "\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    x = self.dense_1(inputs)\n",
        "    y1 = self.dense_2(inputs)\n",
        "    y2 = self.dense_3(y1)\n",
        "    concat = concatenate([x,y2])\n",
        "    return self.softmax(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxrR4TtI6mTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40082ec7-ad5b-4c5e-f360-2105c394811d"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he1BE2PR6mTx"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP-gJaQw6mTx"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbNzzRmQ6mTx"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPlxalCA6mTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5792b1d8-c2af-40cb-a83f-2c58ac006151"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\")\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jkgs5dS6mTy"
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer=\"random_normal\",\n",
        "                             trainable=False)\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\",\n",
        "                             trainable=False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4QdyP2n6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5496d736-3147-42c4-e783-353bc43946c8"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1XwrJiu6mTy"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape=(input_dim, units),\n",
        "                             initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(units,),\n",
        "                             initializer=\"zeros\")\n",
        "    self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                      trainable=False)\n",
        "    self.number_call = tf.Variable(initial_value=0,\n",
        "                                   trainable=False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w)+ self.b\n",
        "    self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "    self.number_call.assign_add(inputs.shape[0])\n",
        "    return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ06knKh6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f9a7bb-ce61-4904-da42-3212785c5c39"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1q20SKO6mTy"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbFYPNZc6mTy"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaaagj9E6mTy"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3 , units_2)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "      x = self.layer_1(inputs)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout_1(x)\n",
        "      x = self.layer_2(x)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout_2(x)\n",
        "      x = self.layer_3(x)\n",
        "\n",
        "      return  self.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roZuZnXQ6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c73d74-d1be-42c3-e18b-52910822e751"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SRNCnBh6mTy"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xR42mXb6mTy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfqPtwwi6mTy"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1nX9gX6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2087d42c-e335-4ce8-bfc4-032f8d2a2211"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5MuykNj6mTy"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kosciXy76mTy"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSby1RZ36mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7e2ae6-cfbb-48b2-d869-fc17026f2dfc"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(LinearLayer, self).__init__()\n",
        "    self.m = self.add_weight(shape=(1,),\n",
        "                            initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(1,),\n",
        "                            initializer=\"zeros\")\n",
        "      \n",
        "  def call(self, inputs):\n",
        "    return self.m*inputs+self.b\n",
        "  \n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yzKcl_n6mTy"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_2otMmU6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f39d1f9-fed0-458d-d3eb-7a36908996f6"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUEPbz676mTy"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZDRJsch6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913a4f10-fbdf-4512-ca68-029ef7422048"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = linear_regression(x_train)\n",
        "    loss = SquaredError(predictions, y_train)\n",
        "\n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "  linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "  print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a4qprsI6mTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "b264b77e-b8d8-410f-a802-5e331da6404a"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSliN9EX6mTy"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUfg5cTW6mTz"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZK4mD0o6mTz"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gawMuGAu6mTz"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Ttx0MJ6mTz"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                             initializer=\"random_normal\",\n",
        "                             name = \"kernel\")\n",
        "    self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer=\"zeros\",\n",
        "                             name =\"bias\")\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "      x = self.layer_1(inputs)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout_1(x)\n",
        "      x = self.layer_2(x)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout_2(x)\n",
        "      x = self.layer_3(x)\n",
        "\n",
        "      return  self.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA9qLwD4HV4U",
        "outputId": "88254cc9-c0b5-415f-ee6d-ea75d6bee214"
      },
      "source": [
        "# Instantiate the model object\n",
        "\n",
        "model = MyModel(64, 64, 46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATMGO46n6mTz"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjzdW6IT6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb64ade-6fcc-4d36-b11c-ced1685dfd2e"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyp8Juo86mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d81ef9-edd3-4b7f-f7f6-824ab291746b"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsD1Lckr6mTz"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-1-EyLP6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c9e063-a5d0-4a3d-94b5-b8430c59f367"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z39iJQTY6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a70630-72f4-4acb-9679-aad1ce6a57c6"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "print(text_news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWoxWfbk6mTz"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzm8ldvs6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d886a2a2-6366-48e5-9d8d-d7ef1c412df4"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61mZPC8v6mTz"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy85Xz_e6mTz"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIP8Z5w76mTz"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjwYcRPT6mTz"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1WLLBy16mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3f981c-ddd7-4a6d-d2e2-aad4adca5342"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))   \n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  # Traininf loop\n",
        "  for x, y in train_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # compute current loss\n",
        "    epoch_loss_avg(loss_value)\n",
        "    # Compare predicted label to actual lable\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  #End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch, epoch_loss_avg.result(),\n",
        "                                                              epoch_accuracy.result()))\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUj6ND6l6mTz"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLd2F-C76mTz"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5-jh7Qb6mTz"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfruI8YO6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ab36c4-c488-4252-bf6a-6366e612ab83"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAm_PaoJ6mTz"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Mimf4N6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "dab9ca58-7b18-4f48-92ea-4c240d5172ec"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPtKnzk6mTz"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvzKULXg6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0d5d4c-1f21-43f0-a924-d3995cf4a2ea"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqtN9WT6mTz"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqaNONk6mTz"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAUaCqSk6mTz"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43jaRJNG6mTz"
      },
      "source": [
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(64, 64, 46)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNMH-d06mTz"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpzVI6t26mTz"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE2J5cns6mTz"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng3VMLXO6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaea438-2865-4f19-c387-496b9ec81cf5"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))   \n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  # Traininf loop\n",
        "  for x, y in train_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # compute current loss\n",
        "    epoch_loss_avg(loss_value)\n",
        "    # Compare predicted label to actual lable\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  #End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch, epoch_loss_avg.result(),\n",
        "                                                              epoch_accuracy.result()))\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXFZbrJQ6mTz"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wliQpToD6mTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66f31d1-c2da-46c0-a92b-897306a78b37"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_7I_gp7NMmf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}