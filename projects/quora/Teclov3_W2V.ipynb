{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/404290 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (15,384) (96,) (15,384) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-29d4d0a8c071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# compute final vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmean_vec1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvec1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmean_vec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_vec1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvecs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (15,384) (96,) (15,384) "
     ]
    }
   ],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 384])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), 384])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}